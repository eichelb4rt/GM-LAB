\documentclass[sigconf, fleqn]{acmart}
\usepackage{booktabs}
\usepackage{placeins}
\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\usepackage{subcaption}


%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% These commands are for a PROCEEDINGS abstract or paper.
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in 

\acmConference[GM LAB]{Graphical Models LAB}{August 9}{Jena, Germany}


\graphicspath{{graphics/}}

\definecolor{myblue}{RGB}{46, 59, 160}
\hypersetup{
    pdfstartpage=1,
    pdfstartview = FitB,
    pdfpagelayout=SinglePage,
    pdftitle={Project Report},
    pdfsubject={Structure Learning},
    pdfauthor={Maurice Wenig},
    pdfcreator={Maurice Wenig},
    pdfproducer={Maurice Wenig},
    pdfkeywords={meta, information, pdf, hyperref, latex},
    colorlinks=true,
    linkcolor=myblue,
    citecolor=myblue
}

%----- new commands
\newcommand{\Romannumeral}[1]{\MakeUppercase{\romannumeral #1}}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\abs}[1]{\left\vert #1 \right\vert}
\newcommand{\norm}[1]{\left\| #1 \right\|}
\newcommand{\skal}[2]{\left\langle #1 | #2 \right\rangle}
\newcommand{\numberthis}{\addtocounter{equation}{1}\tag{\theequation}}
%----- defs
\def\notiff{\mathrel{{\ooalign{\hidewidth$\not\phantom{"}$\hidewidth\cr$\iff$}}}}
\def\R{\mathbb{R}}
\def\bbone{\text{\usefont{U}{bbold}{m}{n}1}}
\def\1{\mathbb{1}}
\def\T{\top}
\def\pa{\text{pa}}
\def\ndy{
    % \textcolor{red} {\hfill not done yet!}
    \reversemarginpar
    \marginpar{\raggedleft\textcolor{red}{\rule{2mm}{2mm}}}
}
\def\ghostline{\hfill\vspace*{-5mm}}

\begin{document}
\title[Project Report]{Project Report\\\large Graphical Models LAB}
\author{Maurice Wenig}
\affiliation{%
	\institution{Friedrich Schiller University Jena}
	\country{Germany}}
\email{maurice.wenig@uni-jena.de}

\maketitle
% \let\thefootnote\relax\footnotetext{AEPRO 2022, March 1, Jena, Germany. Copyright \copyright 2022 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).}


\section{Introduction}
Learning graphical models is a big aspect of machine learning.
But for the parameters of the model to be learned, it is often assumed that the structure is already given, which includes information about dependencies and independencies between features.
However in practice, that is not the case.
Sometimes even the opposite might be true, that the structure between features itself is much more relevant than the actual amplitude of their interactions, with the hope of being able to interpret the interactions (e.g. in a causal context).
This is also an inspiration for our assignment, where our main task is coming up with a search strategy to find a sparse Bayesian Network that fits the data we were given.

For our assignment, we focused on Gaussian Bayesian Networks (GBN).
A GBN is a Bayesian Network where the conditional distributions of a feature given their parents is a Gaussian.
Another constraint to the GBN is that the mean paramater of the Gaussian, that is the conditional distribution, can only depend linearly on the values of the feature's parents in the Network Graph.
So with $n$ as the total number of features, the problem of learning the distribution $p(x_i | x_{\pa(i)})$ for a feature $i \in [n]$, its value $x_i \in \R$, and the value of their parents $x_{\pa(i)} \in \R^{n_i}$ is equivalent to learning $\hat{\beta_i}^* \in \R, \hat{\beta_i} \in \R^{n_i}, \hat{\sigma_i} \in \R$ such that $p(x_i | x_{\pa(i)}) \sim \mathcal{N}(\hat{\beta_i}^* + \hat{\beta_i}^\T x_{\pa(i)}, \hat{\sigma_i}^2)$.
Now for these parameters, the ML-estimates have a simple closed-form solution (it is just linear regression), so finding the best parameters for any given structure is simple and efficient.

% https://doi.org/10.1016/j.dss.2009.05.016
The dataset we were given spans different attributes of Portuguese "Vinho Verde" wine, which was originally used in [cite\ndy].
It consists of twelve features: eleven continuous physicochemical attributes and one discrete sensory attribute (quality).
Here, i will treat quality as a continuous feature.
% TODO: maybe visualize the dataset a bit?
% talk about:
% what is the data?
% what are the attributes?
% maybe some visualization? how does it look?
% what is the task?
% what is it used for? (?)
% what is the problem? (Parameter learning requires the structure to be given. But in pactice, this is not the case. It's rather that the structure is very interesting and needs to be learned. The parameters are then only secondary when it comes to understanding.)
% parameter learning is rather simple because we were constrained to the model of GBN. This means that all parameters have a simple closed-form ML-estimate given the structure.

\FloatBarrier


\section{Methods}
\ndy
% talk about what greedy search algorithm was used (in the overview paper (citation?) they said that it's rather common and well performing, so i chose the greedy algorithm (special case hill climbing with tabu walks and restarts))
% present the hill climbing algorithm (attention! details needed how tabu walks and random restarts are combined! this is not mentioned in the overview)
% -> maybe reasoning needed as to why tabu walks and the random restarts were combined in this way.


\subsection{Hill Climbing}
\ndy
% talk about how you climb the hill (how do you find all of the possible changes at any given point? (you need to check for cycles etc. - how do you do that efficiently (cite the guy)))
% how do you efficiently evaluate the change? (you never copy, the adjacency matrix, but apply the change, see what happens, and revert it)
% how do you evaluate if one change is better than another efficiently? (you never re-calculate the whole objective function, because the changes can be evaluated locally)
% ^ this is further discussed in [Implications for Hill Climbing]


\subsection{Tabu Walks}
\ndy
% talk about how you keep the tabu list efficient
% you hash the adjacency matrix to compressed byte arrays instead of saving 2-dimensional bitstrings and put em in the queue
% then at tabu walk start you put them all into set, this allows you to efficiently compute all changes that are not in the tabu lists, because lookups in the hash set are efficient. (and the number of changes you have to check is huge, so this should save a lot of time)
% maybe say that it uses the same algorithm for finding the best change out of a set of changes as the hill climbing algorithm, just that the set of changes passed is now different (non-tabu changes instead of all possible changes)


\subsection{Random Restarts}
\ndy
% sometimes we just do random changes, maybe talk about your choice of uniform distribution among all possible changes (so we don't have a bias)
% maybe talk about how a bias might be introduced to prioritize additions and deletions, or maybe prioritize flips, idk might be interesting.
% priors for the random walk could be studied in future works. (maybe find out if someone already did that? cite them if someone exists -> like here, they tried but i won't get into it. if you wanna know more about it, check em out)


\subsection{Choice of Optimized Score}
% TODO: rewrite this? this is just for remembering what i did and why
For the score function $p(G | D) \propto p(D | G) \cdot p(G)$, i used the approximation
\begin{align*}
	p(D | G)     & \approx p(D | G, \hat{\theta})               \\
	\hat{\theta} & := \arg\max\limits_{\theta} p(D | G, \theta)
\end{align*}
and the prior
$$p(G) \propto \frac{1}{|E|^\lambda}$$
With this, the objective function can be decomposed into the sum of independent node scores and a regularization term.
\begin{align*}
	\arg\max\limits_G p(G | D) & = \arg\max\limits_G \log p(D | G) + \log p(G)                             \\
	                           & \approx \arg\max\limits_G \log p(D | G, \hat{\theta}) - \lambda \abs{E_G} \\
	                           & = \arg\max\limits_G \sum\limits_{i \in [n]} S_i(G) - \lambda \abs{E_G}
\end{align*}
where
$$S_i(G) := -\abs{D} \cdot \log \hat{\sigma_i} - \frac{1}{2} \sum\limits_{x \in D} \left(\frac{x_i - (\hat{\beta_i}^\T x_{\pa(i)} + \hat{\beta_i}^*)}{\hat{\sigma_i}}\right)^2$$
and $\hat{\theta} := \left(\hat{\beta_i}, \hat{\beta_i}^*, \hat{\sigma_i}\right)_{i \in [n]}$ are the respective ML estimates for
$$p(x_i | x_{\pa(i)}) \sim \mathcal{N}(\hat{\beta_i}^\T x_{\pa(i)} + \hat{\beta_i}^*, \sigma_i^2)$$
A derivation of this can be found in \autoref{sec:calc:score_function}.

\subsubsection{Implications for Hill Climbing}
Elementary changes (addition, substraction, flip of an edge) only influence local distributions.
That means if we construct a graph $G'$, where $G'$ was made by applying an elementary change to an edge $(u, v)$ in $G$, the comparison $p(G' | D) > p(G | D)$ can be evaluated locally:
\begin{align*}
	\sum\limits_{i \in [n]} S_i(G') - \lambda \abs{E_{G'}}                               & > \sum\limits_{i \in [n]} S_i(G) - \lambda \abs{E_{G}}                  \\
	\iff\sum\limits_{i \in [n]} S_i(G') - S_i(G)                                         & > \lambda (\abs{E_{G'}} - \abs{E_{G}})                                  \\
	\iff\underbrace{\sum\limits_{i \in \set{u,v}} S_i(G') - S_i(G)}_{:= \Delta_S(G', G)} & > \lambda \underbrace{(\abs{E_{G'}} - \abs{E_{G}})}_{:= \Delta_E(G',G)}
\end{align*}
Where the second equivalence holds because $S_i(\cdot)$ only depends on node $i$ and its parents.
Therefore $S_i(G') = S_i(G)$ for $i \notin \set{u, v}$.
Note that $\Delta_E(G',G)$ only depends on the type of change applied to $G$:
$$
	\Delta_E(G',G) = \begin{cases}
		1  & \text{addition} \\
		0  & \text{flip}     \\
		-1 & \text{deletion} \\
	\end{cases}
$$
$\Delta_S(G', G)$ measures the improvement of node scores when the change is applied to $G$.

Similarly, two alterations $G_1$ and $G_2$ of $G$ can be compared:
\begin{align*}
	\sum\limits_{i \in [n]} S_i(G_1) - \lambda \abs{E_{G_1}} & > \sum\limits_{i \in [n]} S_i(G_2) - \lambda \abs{E_{G_2}} \\
	\iff \Delta_S(G_1, G) - \Delta_S(G_2, G)                 & > \lambda \left(\Delta_E(G_1,G) - \Delta_E(G_2,G)\right)   \\
\end{align*}
A derivation of this can be found in \autoref{sec:calc:comparison}.

The interpretation of this is that a change has to bring an improvement of at least $\lambda$ per edge in order to improve the whole objective function.
But more importantly, this allow a very efficient comparison of two different changes, which we need to efficiently find the best possible change for [Hill Climbing] and [Tabu Walks]


\subsection{Parameter Fine-Tuning}
\ndy
% how did you fine tune the parameters? what are we looking for? (for the tabu walk and the random restarts to actually climb out of local optima and result in better optima)
% include your funny little plots here


\section{Results}
\subsection{Generated Structures}
\ndy
% refer to some generated graphs for different lambdas that are visualized in the appendix
% idk look at the graphs and maybe there's something to note?
% yes there def is: how sparse is a graph for a given lambda? -> include the plot


\subsection{Performance}
% for different lambdas, sizes of tabu walks, sizes of random walks -> include specs in appendix!
Some performance analysis\ndy


\subsection{Likelihood}
\label{sec:results:likelihood}
% you gotta run this over night or something. Just specify a number of lambdas and do a double-cross validation data = (train_structure, test_structure) = (train_structure, (train_params, test_params))
% -> maybe only 3 rotations in the structure split
Cross validation time.\ndy
\begin{table}[htbp]
	\caption{Error Score Comparison}
	\label{tab:results:errors}
	\begin{tabular}{lrrr}
		\toprule
		Recommender   & RMSE  & MAE   \\
		\midrule
		user based    & 0.670 & 0.301 \\
		item based    & 0.569 & 0.222 \\
		factorization & 0.512 & 0.207 \\
		hybrid        & 0.496 & 0.193 \\
		\bottomrule
	\end{tabular}
\end{table}
\FloatBarrier


\subsubsection{Submission Scores}
\ndy
% talk about how your learned structures fucking rule on the submission website we got, especially on the sparse side.
% (maybe introduce the submission website first tho - we could anonymously submit our learned structures, and they were evaluated on an secret test dataset)


\section{Conclusion}
Some conclusion.\ndy
% i made a pretty efficient greedy search algorithm with tabu walks and random restarts that out-performs the other submitting contestants on the sparse side and is on-par on the not-so-sparse side
% (why is it efficient - because of avoiding copying adjacency matrices and efficient local comparisons of the difference in the objective function that a change brings)
% performance depends on (probably lambda, number of tabu matrices stored, length of tabu walk)
% future work could speed this up by implementing everything in faster programming languages like C++, and maybe try parallelizing the search for the best possible change.


\typeout{}
\bibliographystyle{ACM-Reference-Format}
\bibliography{literature}\ndy


\clearpage
\appendix
\section{Calculations}
\subsection{Score Function}
\label{sec:calc:score_function}
Here we derive
$$\max\limits_G \log p(D | G, \hat{\theta}) = \max\limits_G \sum\limits_{i \in [n]} S_i(G)$$
\begin{flalign*}
	&\max\limits_G \log p(D | G, \hat{\theta})= \max\limits_G \log \left[\prod\limits_{x \in D} p(x | G, \hat{\theta})\right]&&\\
	&= \max\limits_G \log \left[\prod\limits_{x \in D} \prod\limits_{i \in [n]} p(x_i | x_{\pa(i)}, \hat{\beta_i}, \hat{\beta_i}^*, \hat{\sigma_i})\right]&&\\
	&= \max\limits_G \sum\limits_{x \in D} \sum\limits_{i \in [n]} \log p(x_i | x_{\pa(i)}, \hat{\beta_i}, \hat{\beta_i}^*, \hat{\sigma_i})&&\\
	&= \max\limits_G \sum\limits_{x \in D} \sum\limits_{i \in [n]} \log \left[\frac{1}{\sqrt{2\pi} \sigma_i} \exp \left(-\frac{1}{2}\left(\frac{x_i - (\hat{\beta_i}^\T x_{\pa(i)} + \hat{\beta_i}^*)}{\sigma_i}\right)^2\right)\right]&&\\
	&= \max\limits_G \sum\limits_{x \in D} \sum\limits_{i \in [n]} \left[-\frac{1}{2} \left(\frac{x_i - (\hat{\beta_i}^\T x_{\pa(i)} + \hat{\beta_i}^*)}{\sigma_i}\right)^2 - \log \hat{\sigma_i} - \frac{1}{2} \log 2\pi\right]&&\\
	&= \max\limits_G \sum\limits_{i \in [n]} \underbrace{\left[-\abs{D} \cdot \log \hat{\sigma_i} - \frac{1}{2} \sum\limits_{x \in D} \left(\frac{x_i - (\hat{\beta_i}^\T x_{\pa(i)} + \hat{\beta_i}^*)}{\hat{\sigma_i}}\right)^2\right]}_{= S_i(G)}\qed&&
\end{flalign*}
Note that $\hat{\theta}$ ($\hat{\beta_i}, \hat{\sigma_i}$) depends on $G$ ($\pa(i)$).

\subsection{Graph Comparison}
\label{sec:calc:comparison}
For a graph $G'$ that was made by applying one elementary change to a graph $G$, it holds that
\begin{equation}
	\sum\limits_{i \in [n]} S_i(G') = \sum\limits_{i \in [n]} S_i(G) + \Delta_S(G', G) \label{comp_1}
\end{equation}
and
\begin{equation}
	\abs{E_{G'}} = \abs{E_{G}} + \Delta_E(G', G) \label{comp_2}
\end{equation}
Therefore
\begin{align*}
	\sum\limits_{i \in [n]} S_i(G_1) - \lambda \abs{E_{G_1}}                                  & > \sum\limits_{i \in [n]} S_i(G_2) - \lambda \abs{E_{G_2}} \\
	\stackrel{\eqref{comp_1},\eqref{comp_2}}{\iff} \Delta_S(G_1, G) - \lambda \Delta_E(G_1,G) & > \Delta_S(G_2, G) - \lambda \Delta_E(G_2,G)               \\
	\iff \Delta_S(G_1, G) - \Delta_S(G_2, G)                                                  & > \lambda \left(\Delta_E(G_1,G) - \Delta_E(G_2,G)\right)   \\
\end{align*}


\end{document}
\endinput
